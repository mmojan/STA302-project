---
title: "ProjectPart3"
output: pdf_document
date: "2023-10-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Cleaning

```{r}
original_sales<-read.csv("Video_Games.csv")
# make a copy of the dataset
sales<-original_sales

# remove all rows that have N/A or empty information
sales<-sales[is.na(sales$User_Count)==FALSE,]
sales<-sales[is.na(sales$Critic_Count)==FALSE,]
sales<-sales[is.na(sales$Developer)==FALSE,]
sales<-sales[is.na(sales$Year_of_Release)==FALSE,]
sales<-sales[sales$Year_of_Release!="N/A",]

#Changing User_Score from a categorical variable into a numerical variable
sales$User_Score<-as.numeric(sales$User_Score)
sales<-sales[,-c(5,6,7,8,9,12,14,15,16)] #Erase the columns we don't need
sales<-sales[sales$Year_of_Release>2000,] #Limit years higher than 2000
sales<-as.data.frame(sales)
#dim(sales)
#names(sales)
#summary(sales)

sales$Genre2 <- sales$Genre # New variable
sales$Genre2[sales$Genre2=="Role-Playing"]<-"Role"
#Remove less popular categories
sales<-sales[sales$Genre2!="Simulation",]
sales<-sales[sales$Genre2!="Puzzle",]
sales<-sales[sales$Genre2!="Adventure",]
sales<-sales[sales$Genre2!="Strategy",]
sales<-sales[sales$Genre2!="Fighting",]
sales<-sales[sales$Genre2!="Misc",]
sales<-sales[sales$Genre2!="Platform",]
table(sales$Genre2)

#Changing year from a categorical variable into a numerical variable
sales$Year_of_Release<-as.numeric(sales$Year_of_Release)
#table(sales$Year_of_Release)

sales<-sales[,-c(4)] # Drop the original variable of Genre and leave only Genre2
#summary(sales)

table(sales$Platform)
sort(table(sales$Platform))
#boxplot(logSales~sales$Platform)
sales$Platform2 <- sales$Platform # New variable
#Remove less popular categories
sales<-sales[sales$Platform2!="DC",]
sales<-sales[sales$Platform2!="PS",]
sales<-sales[sales$Platform2!="WiiU",]
sales<-sales[sales$Platform2!="PSV",]
sales<-sales[sales$Platform2!="3DS",]
sales<-sales[sales$Platform2!="GBA",]
sales<-sales[sales$Platform2!="XOne",]
sales<-sales[sales$Platform2!="PS4",]
sales<-sales[sales$Platform2!="GC",]
sales<-sales[sales$Platform2!="DS",]
sales<-sales[sales$Platform2!="PSP",]
sales<-sales[sales$Platform2!="Wii",]

table(sales$Platform2)
#boxplot(logSales~sales$Platform2)
#summary(sales)

sales<-sales[,-c(2)] #Drop the original variable of Platform and leave only Platform2
summary(sales)

write.csv(sales,file="VideoGamesSales.csv")

```
## Fitting the Model

```{r}

sales <- data.frame(read.csv("VideoGamesSales.csv"))
model <- lm (Global_Sales ~ Critic_Score + User_Score + Platform2 + Year_of_Release + Genre2, data = sales)
model_1 <- summary(model) 
model_1

coef_table <- data.frame(
  Coefficient = rownames (model_1$coefficients),
  Estimate = model_1$coefficients [, 1],
  Std.Error = model_1$coefficients [, 2],
  T.Value = model_1$coefficients [, 3], 
  P.Value = model_1$coefficients [, 4]
)
# R-squared value
r_squared <- model_1$r.squared
# Print the coefficient table and R-squared 
print(coef_table)
cat (paste("R-squared: ", round (r_squared, 4), "\n"))
```
## Checking MLR Conditions
Let's check the additional conditions for multiple linear models:
1. Conditional mean response condition
2. Conditional mean predictor condition
Let's make a scatterplot of our response versus fitted values to check condition 1.
```{r}
y_hat <- fitted(model)
plot(x = y_hat, y = sales$Global_Sales, main="Response vs Fitted", xlab="Fitted Values", ylab="Global Sales (in millions)")
abline(a = 0, b = 1, lty=2)
```

Based on this plot, we don't observe random diagonal scatter or an easily identifiable non-linear trend so the 1st condition does not seem to hold. As a result, the residual plots will not be reliable.

Next, let's check the 2nd condition.
```{r}
# a new dataframe with only the numerical predictors
new <- subset(sales, select = c(Critic_Score, User_Score, Year_of_Release))
pairs(new)
```
The 2nd condition seems to be satisfied as we observe a lack of curves or other non-linear patterns.

## Checking Assumptions 
First we make the plot for the residuals versus fitted values.
```{r}
e_hat <- resid(model)
plot(x =y_hat, y = e_hat, main="Residual vs Fitted", xlab="Fitted Values", ylab="Residuals")
```
Then we create the residual versus predictor plots for our numerical predictors (Critic_Score, User_Score, Year_of_Release).
```{r}
plot(x = sales$Critic_Score, y = e_hat, main="Residual vs Critic_Score", xlab="Critic Score", ylab="Residual")
plot(x = sales$User_Score, y = e_hat, main="Residual vs User_Score", xlab="User Score", ylab="Residual")
plot(x = sales$Year_of_Release, y = e_hat, main="Residual vs Year_of_Release", xlab="Year of Release", ylab="Residual")
```
Next we create the residual plots using categorical predictors (Platform, Genre).

```{r}
boxplot(e_hat ~ sales$Platform , main="Residual vs Platform", xlab="Platform", ylab="Residuals")
boxplot(e_hat ~ sales$Genre , main="Residual vs Genre", xlab="Genre", ylab="Residuals")
```

Lastly, we create the QQ plot.
```{r}
qqnorm(e_hat) 
qqline(e_hat)
```
We observe a violation of the normality assumption based on the deviation and curving from the diagonal line that occurs in the QQ plot. 
We also have some evidence of a violation of the constant variance assumption due to the increase of the spread shown in the residual vs fitted, residual vs user_score, and residual vs critic_score plots.
We also have evidence of a violation of the linearity assumption since we observe some systemic patterns in the residual vs fitted, residual vs user_score, and residual vs critic_score plots.
As we don't observe any large clusters if points or patterns across time we don't have a violation of the uncorrelated errors assumption.

## Transformations

We apply Box-Cox transformation to the response to mitigate the observed violation of the linearity assumption.
```{r}
# Transformation on Y
library(car)
boxCox(model)
```
The 95% Cl on MLE is very close to 0 so ln transformation is reasonable.
Based on the transformation on y, we fit a new model:
```{r}
model_ln <- lm (log(Global_Sales) ~ Critic_Score + User_Score + Platform2 + Year_of_Release + Genre2, data = sales)
summary(model_ln)
```
After fitting this new model, we once again check the MLR additional conditions and check for assumption violations.

```{r}
# condition 1
y_hat <- fitted(model_ln)
plot(x = y_hat, y = sales$Global_Sales, main="Response vs Fitted", xlab="Fitted Values", ylab="Global Sales (in millions)")
abline(a = 0, b = 1, lty=2)
```
Based on this plot, we don't observe random diagonal scatter or an easily identifiable non-linear trend so the 1st condition does not seem to hold. As a result, the residual plots will not be reliable.
Condition 2 still holds as previously shown.
Now we check the assumptions one again.
```{r}
# residuals versus fitted values
e_hat <- resid(model_ln)
plot(x =y_hat, y = e_hat, main="Residual vs Fitted", xlab="Fitted Values", ylab="Residuals")
```

```{r}
# residual versus predictor plots for numerical variables
plot(x = sales$Critic_Score, y = e_hat, main="Residual vs Critic_Score", xlab="Critic Score", ylab="Residual")
plot(x = sales$User_Score, y = e_hat, main="Residual vs User_Score", xlab="User Score", ylab="Residual")
plot(x = sales$Year_of_Release, y = e_hat, main="Residual vs Year_of_Release", xlab="Year of Release", ylab="Residual")
```

```{r}
# residual plots for categorical predictors
boxplot(e_hat ~ sales$Platform , main="Residual vs Platform", xlab="Platform", ylab="Residuals")
boxplot(e_hat ~ sales$Genre , main="Residual vs Genre", xlab="Genre", ylab="Residuals")
```

```{r}
# QQ plot
qqnorm(e_hat) 
qqline(e_hat)
```

Based on the new plots we don't observe any assumption violations.
Next we perform ANOVA test of overall significance to identify the existence of a linear relationship (null hypothesis: all slopes are zero).
```{r}
summary(model_ln)
```
From the summary table we can see that the p-value is 2.2e-16 which is less than $\alpha$ = 0.05. So we reject the null and conclude a statistically significant linear relationship exists for at least one predictor.

Next, we perform hypothesis tests for individual coefficients in our model (with the null hypothesis being that the coefficient is 0).
```{r}
summary(model_ln)
```

Based on the Pr(>|t|) column in the summary table we reject the null and claim a significant linear relationship exists for all the coefficients ($Pr(>|t|)$ is less than $\alpha$ = 0.05 for all coefficients). As all coefficients are significant, we can't make a more reduced model to perform a partial F test and we choose the current model as our final one.